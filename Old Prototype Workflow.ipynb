{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f00062d-0f67-46b5-aca0-b7857d11c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huanxing/Documents/GitHub/Analogical-LLM/analogical-lc-env/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "import openai \n",
    "# from langgraph_supervisor import create_supervisor\n",
    "from langchain.chat_models import init_chat_model\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c75eb6-69bf-40c9-8ed4-8b96c4d1f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "TARGET_DOMAIN = dedent(\"\"\"\n",
    "        As a Domain Analysis Specialist, extract the core innovation domain from the user query.\n",
    "        Instructions:\n",
    "        1. Analyze the user's input\n",
    "        2. Identify the primary domain requiring innovation\n",
    "        3. Classify it within standard innovation categories\n",
    "        Output Format:\n",
    "        Target Domain: [Clear, specific domain label]\n",
    "        Be very detailed and specific in your response and do not generalize. Respond ONLY with the name of the domain, do NOT include ANY other text like 'Target Domain:'.\n",
    "        User query: {user_query}\n",
    "\"\"\").strip()\n",
    "\n",
    "PROBLEM_LANDSCAPE = dedent(\"\"\"\n",
    "        You are a Problem Landscape Analyst. Your task is to map out the concrete challenges within the target domain identified.\n",
    "        Instructions:\n",
    "        1. Identify 3-5 core problems or challenges currently present in this domain.\n",
    "        2. For each problem, provide:\n",
    "        - Problem: A short, clear title.\n",
    "        - Description: 2-3 sentences explaining what the problem is and why it matters.\n",
    "        - Context: Briefly state the circumstances or environment where this problem occurs.\n",
    "        - Stakeholders: List the main groups or individuals affected.\n",
    "        - Root Causes: Identify 1-3 underlying causes, if known.\n",
    "        - Impact: State the significance of the problem (e.g., social, economic, technical).\n",
    "        - Current Approaches: How is this problem currently addressed?\n",
    "        - Limitations: What are the shortcomings of current approaches?\n",
    "        - Success Metrics: How would you measure if this problem is solved?\n",
    "        - Interconnections: Note if this problem is linked to or influenced by other problems.\n",
    "        Output Format:\n",
    "        Present your findings as a structured list or JSON array, with each problem fully described as above.\n",
    "        Important:\n",
    "        - Focus on clarity and completeness.\n",
    "        - Avoid abstracting or generalizing; stay concrete and domain-specific.\n",
    "        - Do not propose solutions; only describe the current problem landscape.\n",
    "        Target domain: {target_domain}\n",
    "\"\"\").strip()\n",
    "\n",
    "ABSTRACTION = dedent(\"\"\"\n",
    "You are a TRIZ Methodology Expert. Transform domain-specific problems into universal contradictions.\n",
    "        Process:\n",
    "        1. For each problem in the problem landscape\n",
    "        - Abstract to universal parameters (what improves vs. what worsens)\n",
    "        - Express as 'When we improve X, Y worsens'\n",
    "        - Ensure parameters are domain-agnostic\n",
    "        2. Identify 3-4 core contradictions:\n",
    "        - Select the most fundamental tensions\n",
    "        - Map to TRIZ contradiction matrix\n",
    "        - Note applicable inventive principles\n",
    "        Output:\n",
    "        # Core Contradictions:\n",
    "        1. Improving [parameter] vs. Worsening [parameter]\n",
    "        - TRIZ Principles: [1-3 relevant principles]\n",
    "        - Innovation Potential: [High/Medium/Low]\n",
    "        - Universal Application: [Brief example from another domain]\n",
    "        Focus on contradictions that, if resolved, would create breakthrough value.\n",
    "\n",
    "        Problem landscape: {problem_landscape}\n",
    "\"\"\").strip()\n",
    "\n",
    "BASE_DOMAIN = dedent(\"\"\"\n",
    "        You are a Cross-Domain Search Specialist.\n",
    "        For each contradiction provided, identify two distinct source domains (fields or industries) where this contradiction has been successfully addressed.\n",
    "        The domains should have A CONCEPTUAL DISTANCE OF AT LEAST 2 DISTINCT HOPS FROM WHAT IMMEDIATELY COMES TO MIND. Be creative! It can be domains within spheres like natural, phsyical, social, artistic, anything.\n",
    "        For each domain, briefly explain why it is relevant to the contradiction. Do not describe specific solutions-only list the domains and your rationale.\n",
    "        Output:\n",
    "        A list for each contradiction, naming two relevant domains with a one-sentence rationale for each.\n",
    "\n",
    "        Contradictions: {contradictions}\n",
    "\"\"\").strip()\n",
    "\n",
    "BASE_SOLUTIONS = dedent(\"\"\"\n",
    "        You are a Solution Pattern Extractor. You are provided with an input with 2 base domains identified per contradiction.\n",
    "        For each of these identified base domains , identify one specific, well-documented solution pattern within the domain that effectively resolves the contradiction.\n",
    "        For each solution pattern:\n",
    "        - The original base domain identified\n",
    "        - The name or label of the solution pattern\n",
    "        - A detailed description of the core mechanism or principle involved and how it addressed the domain's contradiction\n",
    "        - The context or situation in the domain where this pattern is applied\\n\"\n",
    "        Do not generalize or adapt the solution-simply describe how the contradiction is addressed within each source domain.\n",
    "        Output:\n",
    "        For each of the provided domain, list the base domain name, solution pattern name, a detailed description of its mechanism, and the context in which it is used.\n",
    "\n",
    "        Input: {input}\n",
    "\"\"\").strip()\n",
    "\n",
    "ANALOGICAL_TRANSFER = dedent(\"\"\"\n",
    "You are an Analogical Transfer Specialist.\n",
    "\n",
    "Your task is to propose how solution patterns used to resolve abstracted contradictions in various base domains might inspire solution framings for the original target domain.\n",
    "\n",
    "Input:\n",
    "1. A list of abstracted contradictions, each with two base domains and their associated solution patterns (including how each contradiction was resolved in those domains).\n",
    "2. The original target domain.\n",
    "\n",
    "Instructions:\n",
    "For each contradiction, review the solution patterns from both base domains. For each pattern:\n",
    "- Analyze the core mechanism or principle behind the solution.\n",
    "- Map and adapt this mechanism conceptually to the target domain, considering the specific context and needs of the target domain.\n",
    "- Clearly describe how this analogical transfer could frame a potential solution in the target domain.\n",
    "- Highlight any key adaptations, considerations, or limitations that would be relevant when applying this pattern to the target domain.\n",
    "\n",
    "Output:\n",
    "For each contradiction and base domain solution pattern, provide a comprehensive description of a proposed solution framing for the target domain, including:\n",
    "- The original contradiction addressed\n",
    "- The source domain and solution pattern\n",
    "- A detailed explanation of how the pattern could inspire or inform a solution in the target domain\n",
    "- Any important adaptations or considerations for successful transfer\n",
    "\n",
    "Input:\n",
    "- List of abstracted contradictions: {contradictions_solutions}\n",
    "- Original target domain: {target_domain}\n",
    "\"\"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e573d7e-e43f-4c7d-8752-ae11a6198c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please provide your OPENAI_API_KEY ········\n"
     ]
    }
   ],
   "source": [
    "# check for openai API\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a188a9e3-c538-487f-9dde-8dfe295575db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph state: workflow\n",
    "class ReasoningState(TypedDict):\n",
    "    user_query: str\n",
    "    target_domain: str\n",
    "    problem_landscape: str\n",
    "    abstraction: str\n",
    "    base_domain: str\n",
    "    base_solutions: str\n",
    "    analogical_transfer: str\n",
    "    solution: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306439ab-4b94-4084-8a1c-8c53ecf1a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can switch between different LLMs \n",
    "llms = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ea64a9-96a1-42ab-bb3d-1a1c1d14b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Agent: Identify Target Domain from User Input\n",
    "def target_domain_agent(state: ReasoningState):\n",
    "    u = state['user_query']\n",
    "\n",
    "    msg = llms.invoke(TARGET_DOMAIN.format(user_query=u))\n",
    "\n",
    "    return {\"target_domain\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d327c06e-9618-4463-b19e-2be74a21d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2st Agent: Conduct comprehensive research into problem landscape for target domain \n",
    "# (i.e. What specific challenges exist in this domain?)\n",
    "def problem_landscape_agent(state: ReasoningState):\n",
    "    t = state['target_domain']\n",
    "\n",
    "    msg = llms.invoke(PROBLEM_LANDSCAPE.format(target_domain=t))\n",
    "\n",
    "    return {\"problem_landscape\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b96ec9-7bdb-4803-9bab-dcc82d6a4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Agent: Abstract Problems Identified into Generalized Principles and TRIZ Contradiction\n",
    "def abstraction_agent(state: ReasoningState):\n",
    "    p = state['problem_landscape']\n",
    "\n",
    "    msg = llms.invoke(ABSTRACTION.format(problem_landscape=p))\n",
    "\n",
    "    return {\"abstraction\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e95a5d2f-1773-4339-ba89-995d185885c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th Agent: Search for Appropriate Base Domains\n",
    "def base_domain_agent(state: ReasoningState):\n",
    "    a = state['abstraction']\n",
    "\n",
    "    msg = llms.invoke(BASE_DOMAIN.format(contradictions=a))\n",
    "\n",
    "    return {\"base_domain\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7db11f3-e388-48b4-8661-cde636b1ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th Agent: Identify Solution in Base Domain\n",
    "def base_solution_agent(state: ReasoningState):\n",
    "    b = state['base_domain']\n",
    "\n",
    "    msg = llms.invoke(BASE_SOLUTIONS.format(input=b))\n",
    "\n",
    "    return {\"base_solutions\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc1b395-b154-493e-9c57-7e5a6926cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th Agent: Base Domain Solution Informing Target Domain Solution\n",
    "def analogical_transfer_agent(state: ReasoningState):\n",
    "    if \"base_solutions\" not in state:\n",
    "        raise ValueError(\"Missing 'base_solutions' key. Check if previous node returned it.\")\n",
    "    b = state['base_solutions']\n",
    "    t = state['target_domain']\n",
    "    \n",
    "    msg = llms.invoke(ANALOGICAL_TRANSFER.format(contradictions_solutions=b, target_domain = t))\n",
    "\n",
    "    return {\"analogical_transfer\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3626041-fcd5-4bf3-a32b-f164352e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7th Agent: Summarize everything and respond to the question\n",
    "def synthesis_agent(state: ReasoningState):\n",
    "    msg = llms.invoke(\n",
    "        f\"Evaluate the proposed analogical solutions. Find the best one that balances practicality with innovation. Then, provide a detailed, well-structured response that addresses all aspects of the query.\\n\\n\"\n",
    "        f\"Problem: {state['user_query']}\\n\"\n",
    "        f\"Analogical Solutions: {state['analogical_transfer']}\"\n",
    "        f\"In your output, remember to abstract away the analogy itself such that it is focused on responding to the user input.\"\n",
    "    )\n",
    "    return {\"solution\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68994430-5388-4c63-84be-919d5978d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the workflow \n",
    "workflow = StateGraph(ReasoningState)\n",
    "\n",
    "workflow.add_node(\"target\", target_domain_agent)\n",
    "workflow.add_node(\"landscape\", problem_landscape_agent)\n",
    "workflow.add_node(\"abstract\", abstraction_agent)\n",
    "workflow.add_node(\"base\", base_domain_agent)\n",
    "workflow.add_node(\"base_soln\", base_solution_agent)\n",
    "workflow.add_node(\"analogy\", analogical_transfer_agent)\n",
    "workflow.add_node(\"synthesis\", synthesis_agent)\n",
    "\n",
    "workflow.set_entry_point(\"target\")\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(\"target\", \"landscape\")\n",
    "workflow.add_edge(\"landscape\", \"abstract\")\n",
    "workflow.add_edge(\"abstract\", \"base\")\n",
    "workflow.add_edge(\"base\", \"base_soln\")\n",
    "workflow.add_edge(\"base_soln\", \"analogy\")\n",
    "workflow.add_edge(\"analogy\", \"synthesis\")\n",
    "\n",
    "workflow.set_finish_point(\"synthesis\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5235345-734c-4aae-a32b-82acc97ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q = \"I have an idea that I want to brainstorm with you. I'm not sure what problem I'm going to solve yet, but this is still something interesting to me. For background, I worked on a project called Anonymix, where we take a life story interview transcript from different individuals, convert these textual 'personas' to persona graph (with different types of nodes), and then identified graph clusters using louvain's method to shuffle them across personas to create shuffled persona. This preserves privacy while still making sure that individual agents are sufficiently realistic. Now, I'm going to work at whyhow.ai which is going to use knowledge graph RAG for enterprise use cases like legal and healthcare where accuracy and relevance of information retrieval is of paramount importance. I realised that graphs - knowledge graph in this case - are amazing tools that I want to learn more about. Specifically, I want to understand deeply, at a fundamental level, what *possibilities* it enables, and where might I be able to apply this to. For example, I guess I can take any sort of unstructured input and KG can construct a structured representation of them in a non-hierarchical manner. This is also the way that Roam Research and Logseq works and the core of their value proposition in terms of how they differ as a personal knowledge management system as compared to the hierarchical way of organising information that Notion or Evernote adopts. I can even imagine an enterprise or interpersonal use case, where IF everyone uses the same diary app that's private to themselves but me as the 'admin' behind the scene could see everything, then I could 'engineer serendipity' from, for example, identifying and suggesting to individuals with this same community that 'hey, person X is also thinking along similar lines as what you're thinking (but with a twist!). It'd be good to go find him for a chat, I'm sure you'll love it!'. This is 'engineered serendipity' that's still sufficiently serendipitous nevertheless because, for example, it's not just matching people based on what they PUBLICLY put out there but based on what they privately notes. Specifically, it tries to identify the common underlying 'values' and 'nuances' behind these private notes instead of connecting individuals based on the exact content of the private notes themselves. However, for this to work, I guess there need to have a common input channel that everything in the community would use, and I'm not sure how realistic is it going to be. Help me understand from first principles what this tech (representing ... as KG) might enable. The 'engineered serendipity' idea is an example of what I've thought of but it's not too practical yet. Then, after you've given me an in-depth exploration of the possibilities in terms of first principles, help me ideate 3 different project ideas I could actualize on. Give me rationale for why these might be difficult without the tech (representing ... as KG), an why the projects are tackling a real problem (rationale).  Let's explore the possibilities together!\"\n",
    "input_state = {\"user_query\": test_q}\n",
    "\n",
    "final_state = graph.invoke(input_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6aa161c-0873-49c4-9bcc-85d644311d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love your curiosity and the rich context you've provided! You're at a fascinating intersection of privacy-preserving persona synthesis, knowledge graphs, and structured information retrieval, with an awareness of both individual and organizational use cases. Let's break this down step by step:\n",
      "\n",
      "## First-principles Exploration: What Does Representing X as a Knowledge Graph Enable?\n",
      "\n",
      "### 1. Non-Hierarchical, Multi-Relational Organization\n",
      "- Unlike trees/hierarchies (folders, tags), a graph allows any node (entity) to connect to any other via typed/arbitrary relations.\n",
      "- This supports *emergent structure*: Patterns, clusters, and paths that weren't intentionally designed, but naturally arise from the data.\n",
      "- Example: Roam/Logseq let you freely link, forming a mesh of knowledge. This makes surprising connections and shortcuts possible.\n",
      "\n",
      "### 2. Powerful Queries and Reasoning\n",
      "- KG allows graph-centric queries: shortest paths, neighborhood exploration, clustering, link prediction, path-based recommendations, etc.\n",
      "- Fundamentally transforms retrieval from \"what folder is this in?\" to \"how does this connect to X, Y, or Z?\" or \"who/what relates most interestingly to what I'm working on?\"\n",
      "\n",
      "### 3. Semantic Richness and Abstraction\n",
      "- Nodes can represent diverse entities (people, concepts, locations, orgs, events, values).\n",
      "- Edges can encode nuanced relationships (friend-of, inspired-by, uses, is-contrary-to).\n",
      "- Allows for multiple, overlapping, evolving ontologies.\n",
      "\n",
      "### 4. Cross-context Reasoning\n",
      "- Data from different domains/sources can be merged as long as you can model their connections.\n",
      "- Enables discovery of cross-domain analogies, influences, and transfer learning.\n",
      "\n",
      "### 5. Privacy-Preserving Synthesis and Abstraction\n",
      "- You can abstract away identifying information, synthesize \"summary nodes,\" or shuffle graph clusters (as in your Anonymix work) for privacy/anonymity.\n",
      "- Identifies \"structural equivalence\" between entities, not just textual similarity.\n",
      "\n",
      "### 6. Agency and Personalization\n",
      "- For individuals, you can model personal knowledge, projects, or notes as mini-KGs.\n",
      "- For organizations, you can build a *living map* of expertise, ideas, dependencies, risks, or opportunities.\n",
      "\n",
      "### 7. Dynamic, Adaptive Structures\n",
      "- Graphs aren't static—the topology evolves as information and relationships evolve.\n",
      "- Suitable for capturing *living* knowledge (unlike rigid tables or folders).\n",
      "\n",
      "#### Summary Table\n",
      "\n",
      "| Property                 | Trees/Lists | Tags       | Knowledge Graphs          |\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "=== | ===\n",
      "| Structure                | Hierarchical| Flat       | Networked/relational      |\n",
      "| Multi-relational         | No          | Limited    | Yes                       |\n",
      "| Emergent patterns        | Hard        | Limited    | Yes (clusters, paths...)  |\n",
      "| Semantic expressivity    | Low         | Medium     | High                      |\n",
      "| Query power              | Limited     | Some       | Very high (graph search)  |\n",
      "| Privacy preservation     | Manual      | Manual     | Natural (subgraph, abstraction, shuffling) |\n",
      "\n",
      "\n",
      "=== ## Potential Possibilities & Their “Why Nots” ===\n",
      "\n",
      "Some new things you can do:\n",
      "\n",
      "- Serendipitous discovery: Find connections along surprising, multi-step paths or via \"structural similarity,\" not mere keyword overlap.\n",
      "- Organizational awareness: Map expertise, dependencies, or redundancies across an enterprise's knowledge, letting you optimize, innovate, or de-risk faster.\n",
      "- Narrative or idea archetypes: Identify recurring \"shapes\" of thoughts, values, or collaborative patterns, not just surface-level content.\n",
      "- Privacy-resecting recommender systems: Suggest connections, readings, or collaborations based on abstracted relations, not raw sensitive data.\n",
      "- Self-reflection and synthesis: Help individuals see patterns in their own notes, revealing hidden goals or contradictions.\n",
      "\n",
      "\n",
      "=== ## Three Project Ideas Leveraging KGs (with Rationale & What’s Hard Otherwise) ===\n",
      "\n",
      "### 1. Cognitive Cartographer: Automated Personal Knowledge Graph from Raw Notes\n",
      "\n",
      "Idea:  \n",
      "An app/plugin that ingests your unstructured notes (from Notion, Google Docs, emails, hand-written scans, etc.) and automatically builds a personal knowledge graph. It visualizes connections between ideas, concepts, and topics you’ve written about, identifies clusters, and surfaces “bridge” concepts (i.e., those that connect disparate domains in your thinking).\n",
      "\n",
      "Why is this tough without KGs?\n",
      "- Tagging/foldering won’t reveal non-obvious, multi-hop connections.\n",
      "- Manual linking is tedious and error-prone.\n",
      "- No way to identify emergent clusters or “connector” nodes that might spark breakthroughs or improve recall.\n",
      "\n",
      "Rationale / What problem does it solve?\n",
      "- “Lost knowledge” buried across systems.\n",
      "- Facilitates creativity by surfacing hidden connections.\n",
      "- Assists with writing, research, synthesizing new ideas.\n",
      "\n",
      "\n",
      "=== ### 2. Value-based Serendipity Engine for Private Communities ===\n",
      "\n",
      "Idea:  \n",
      "A privacy-respecting recommender that, given access to individual’s private “journals” (with explicit consent and privacy guarantees), builds abstracted KGs capturing their underlying values/goals/interests. It then facilitates “engineered serendipity” by matching people NOT on superficial keywords, but on shared values, goals, or complementary problem framings—and suggests introductions or small group syncs.\n",
      "\n",
      "Why is this tough without KGs?\n",
      "- Keyword-based recommenders can’t generalize to abstract traits or values.\n",
      "- Community serendipity is currently left to chance or labor-intensive manual match-making.\n",
      "- Maintaining privacy alongside meaningful matching is only possible by abstracting and operating at the graph level, rather than exposing raw text.\n",
      "\n",
      "Rationale / What problem does it solve?\n",
      "- Prevents echo chambers; encourages cross-pollination.\n",
      "- Builds stronger, value-aligned relationships in knowledge work or creative orgs.\n",
      "- Tackles the problem of “hidden potential” in large, loosely connected groups.\n",
      "\n",
      "\n",
      "=== ### 3. Enterprise Contextual Memory for Legal/Healthcare (RAG-augmented) ===\n",
      "\n",
      "Idea:  \n",
      "A tool integrating with enterprise documentation (contracts, case law, policy notes, medical records, clinical trial data) to construct a contextual KG of facts, legal arguments, citations, and precedents. When a query is posed, the retrieval-augmented generation (RAG) pipeline traverses the KG, extracting not just superficially relevant documents, but assembling a *narrative* or “argument path” that shows how different facts and precedents interconnect.\n",
      "\n",
      "Why is this tough without KGs?\n",
      "- Simple search “misses the forest for the trees” (no awareness of how facts connect).\n",
      "- Contextual retrieval (“explain why these things relate”) is brittle without a model of relations.\n",
      "- Compliance, traceability, and accuracy are crucial—KGs let you link back through each inference step.\n",
      "\n",
      "Rationale / What problem does it solve?\n",
      "- Reduces wasted effort in re-finding/connecting relevant legal or medical context.\n",
      "- Improves explainability in high-stakes fields.\n",
      "- Facilitates onboarding, collaboration, and compliance audits.\n",
      "\n",
      "## Bonus: Framing the “Why Now”\n",
      "\n",
      "- Data explosion: Unstructured and fragmented information is everywhere.\n",
      "- LLM + KG = Amazing: LLMs lower the friction for extracting facts, but KGs make them *explainable* and *navigable*.\n",
      "- Privacy anxiety: Synthesizing and abstracting with KGs enables a new class of privacy-aware apps.\n",
      "\n",
      "## Conclusion: “First Principles” for You\n",
      "\n",
      "- Graph representations are fundamentally about *relationships, context, and emergence*. \n",
      "- They become exponentially more valuable with scale, diversity, and dynamism of input.\n",
      "- They enable queries, inferences, and discoveries that would otherwise be infeasible or brittle.\n",
      "- They facilitate privacy, explainability, and serendipity in complex, evolving systems.\n",
      "\n",
      "You’re right on the edge of something powerful! Let me know if you want a deeper dive into any of the above, or if you'd like concrete technical advice for bootstrapping one of these projects.\n"
     ]
    }
   ],
   "source": [
    "result = basic_output(test_q)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "750d99f1-e935-4250-82dd-d110d2e098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_output\n",
    "import re\n",
    "\n",
    "def parse_solution(text):\n",
    "    # Remove Markdown formatting like \"**\" and \"\\n\"\n",
    "    clean_text = text.replace(\"**\", \"\").replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # Split into sections by horizontal rules (---)\n",
    "    sections = re.split(r'-{3,}', clean_text)\n",
    "\n",
    "    # Create a readable version of each section\n",
    "    readable_output = []\n",
    "    for section in sections:\n",
    "        section = section.strip()\n",
    "        if not section:\n",
    "            continue\n",
    "        # Optional: separate title and body if present\n",
    "        lines = section.split(\"\\n\")\n",
    "        if len(lines) > 1 and \":\" not in lines[0]:\n",
    "            # First line is likely a heading\n",
    "            heading = lines[0]\n",
    "            body = \"\\n\".join(lines[1:])\n",
    "            readable_output.append(f\"\\n=== {heading} ===\\n{body}\")\n",
    "        else:\n",
    "            readable_output.append(section)\n",
    "\n",
    "    return \"\\n\\n\".join(readable_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c40e70ac-30df-4ae1-bbfd-3b3cf4db43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all parsed outputs to a text file\n",
    "with open(\"sample_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for key in final_state:\n",
    "        raw_output = str(final_state[key])  # Ensure it's a string\n",
    "        final_output = parse_solution(raw_output)\n",
    "        f.write(f\"\\n### {key} ###\\n\")\n",
    "        f.write(final_output)\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b68a71d-9193-4005-ac65-5a668d06b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline for comparison\n",
    "def basic_output(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5a4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output(test_q)\n",
    "\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline ===\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "400da2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educators seeking to balance the benefits of teamwork with clear evidence of individual mastery can redesign their system by interweaving individual and group accountability. Here are practical steps, supported by educational research:\n",
      "\n",
      "\n",
      "=== ### 1. Hybrid Assessment Structures ===\n",
      "- Individual-Group Blend: Assign group projects, but require each student to complete an individual component (e.g., reflection, lab report, quiz directly tied to project outcomes).\n",
      "- Two-Tier Grading: Grade both the group product and the individual's understanding (e.g., 50% based on group work, 50% on individual performance).\n",
      "\n",
      "### 2. Pre- and Post-Project Individual Checks\n",
      "- Entry & Exit Tickets: Use short quizzes or prompts before and after the group work to assess what each student knows and has learned.\n",
      "- Oral Explanations: Randomly select students to explain group decisions or project content to ensure everyone is prepared.\n",
      "\n",
      "### 3. Accountability in Role Rotations\n",
      "- Role-Specific Tasks: When assigning rotating roles, require each student to submit a summary of their contributions or findings aligned with their current role.\n",
      "- Self and Peer Scoring: Continue using peer evaluations, but link these directly to individual accountability measures (e.g., require justification and examples).\n",
      "\n",
      "### 4. Scaffolded Supports\n",
      "- Structured Group Norms: Teach explicit standards for group work and collaboration.\n",
      "- Guided Reflection: Regular reflections help students track their own learning and contributions, clarifying personal mastery.\n",
      "\n",
      "### 5. Transparent Grading Criteria\n",
      "- Rubrics: Use clearly defined rubrics that separate collaboration skills from subject mastery. Share and discuss these rubrics with students.\n",
      "\n",
      "Example System:\n",
      "\n",
      "1. Project Phase\n",
      "   - Groups complete a science investigation with clearly assigned roles.\n",
      "   - Each student keeps an individual project journal with daily entries reflecting their learning, questions, and role-based tasks.\n",
      "\n",
      "2. Post-Project Phase\n",
      "   - *Individual Quiz*: Administer a quiz covering project content and skills. Scores count significantly in overall grade.\n",
      "   - *Oral Defense*: Each student answers a question about their project; part of their grade is based on individual explanations.\n",
      "\n",
      "3. Reflection & Feedback\n",
      "   - Students and peers complete evaluations, focusing on both collaboration and individual responsibility.\n",
      "\n",
      "Result:  \n",
      "Students benefit from collaborative learning, but must demonstrate personal understanding to receive a high overall grade.\n",
      "\n",
      "Further Reading:\n",
      "- Johnson, D. W., Johnson, R. T., & Smith, K. A. (2014). *Cooperative Learning: Improving University Instruction by Basing Practice on Validated Theory*. Journal on Excellence in College Teaching.\n",
      "- Slavin, R. E. (1996). *Research on Cooperative Learning and Achievement: What We Know, What We Need to Know*. Contemporary Educational Psychology.\n",
      "\n",
      "\n",
      "=== Summary Table ===\n",
      "\n",
      "| Strategy                               | Promotes Teamwork | Ensures Individual Mastery |\n",
      "|\n",
      "\n",
      "|:\n",
      "\n",
      ":|:\n",
      "\n",
      ":|\n",
      "| Group + Individual Grading                 | ✔️                   | ✔️                            |\n",
      "| Pre/post individual quizzes                 | Partial              | ✔️                            |\n",
      "| Role-based individual accountability        | ✔️                   | ✔️                            |\n",
      "| Guided individual reflection                | ✔️                   | ✔️                            |\n",
      "\n",
      "Key Principle:  \n",
      "Align assessment and grading so that each student must demonstrate their own mastery—while still relying on and contributing to the team's collective effort.\n"
     ]
    }
   ],
   "source": [
    "## GPT 4.1 without Analogical Reasoning Without CoT\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cde0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline BUT WITH COT for comparison\n",
    "def basic_output_COT(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    Think step by step.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35361e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH COT ===\n",
      "\n",
      "Certainly! To address the problem—group work fostering teamwork but possibly reducing individual mastery/accountability—educators should reconsider both the design and assessment of group projects. Here’s a step-by-step approach:\n",
      "\n",
      "### Step 1: Diagnose the Core Issues\n",
      "- Observation: Individual post-project quizzes show lower scores than after solo work.\n",
      "- Analysis: Students may be \"hitchhiking\" (letting groupmates do more), or division of labor is masking some students’ conceptual gaps.\n",
      "\n",
      "### Step 2: Set Clear Dual Objectives\n",
      "- Maintain collaboration (teamwork, communication, problem-solving).\n",
      "- Ensure individual understanding and accountability (content mastery).\n",
      "\n",
      "### Step 3: Redesign Project Structure\n",
      "\n",
      "A. Roles and Responsibilities\n",
      "- Continue rotating roles but with defined individual deliverables for each phase.\n",
      "- Example: For a lab report, each student writes a different section (method, results, analysis) tied to understanding key concepts.\n",
      "\n",
      "B. Scaffolding Collaborative Work\n",
      "- Begin each project with an individual “readiness assurance” quiz to ensure base knowledge.\n",
      "- End with a group synthesis where students must teach back or present individually on certain components.\n",
      "\n",
      "### Step 4: Enhance Assessment Methods\n",
      "\n",
      "A. Mix of Individual and Group Grades\n",
      "- Assign a substantial portion (50–70%) of the project grade to individual performance (individual write-ups, oral defenses, or quizzes covering all project content).\n",
      "- The rest can be group-based (final artifact, group process, creativity).\n",
      "\n",
      "B. Individual Accountability During Projects\n",
      "- Use random “spot-checks”: At intervals, ask individuals to explain group decisions or data to the teacher or peers.\n",
      "- Incorporate short, unannounced individual quizzes on group project content.\n",
      "\n",
      "C. Peer Teaching\n",
      "- Each student is responsible for mastering and teaching one aspect of the project to their peers—accountability built-in.\n",
      "\n",
      "D. Reflection Components\n",
      "- Require individual reflections: “What did you learn? Which parts did you struggle with? How did you contribute?” Grade for depth and honesty.\n",
      "\n",
      "### Step 5: Provide Transparency and Feedback\n",
      "- Clearly communicate grading rubrics differentiating individual vs. group components.\n",
      "- Give quick feedback on readiness quizzes so students know where to focus.\n",
      "\n",
      "### Step 6: Monitor and Iterate\n",
      "- After implementing, monitor quiz scores, student feedback, and engagement.\n",
      "- Adjust the ratio of individual:group assessments or frequency of checks as needed.\n",
      "\n",
      "\n",
      "=== ### Sample Project Structure ===\n",
      "\n",
      "| Phase         | Activity           | Accountability Method            | Weight |\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "=== | ===\n",
      "| Project Start | Readiness Quiz     | Individual quiz                  | 20%    |\n",
      "| Project Work  | Group tasks        | Individual section + group work  | 30%    |\n",
      "| Midpoint      | Spot-check/explain | Give oral/written explanation    | 10%    |\n",
      "| Project End   | Group presentation | Individual Q&A (oral exam)       | 20%    |\n",
      "| Post-project  | Individual reflection/quiz | Reflection/quiz        | 20%    |\n",
      "\n",
      "In summary:  \n",
      "Blend group and individual tasks and assessments throughout the project. Ensure individual mastery is measured separately, but still tied to collaborative experiences. Adjust and iterate until you find a balance for your students.\n",
      "\n",
      "Further Reading:  \n",
      "- “Cooperative Learning: Improving University Instruction by Basing Practice on Validated Theory” (Millis, 2010)\n",
      "- “Designing Group Work: Strategies for the Heterogeneous Classroom” (Cohen & Lotan, 2014)\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output_COT(test_q)\n",
    "\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH COT ===\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7f3ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline BUT WITH PROMPT ENGINEERING for comparison (ask it to balance innovativeness with practicality)\n",
    "def basic_output_prompt_engin(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    Try to balance practicality with innovation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e85f2167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH Prompt Engineering ===\n",
      "\n",
      "Certainly! Balancing individual accountability with authentic collaboration is a common challenge in group work. Here’s a multi-pronged, practical-yet-innovative redesign educators can consider:\n",
      "\n",
      "\n",
      "=== 1. Hybrid Assessment Model ===\n",
      "\n",
      "- Personal Assignments Within Group Projects: Structure group projects so that each student is responsible for a distinct sub-task, deliverable, or research component. For example, in a biology project on ecosystems, one might investigate plant species, another animal relationships, etc. Require each member to submit a short individual report, reflection, or data analysis alongside the collective assignment.\n",
      "- Individual “Defense”: After project completion, each student briefly presents or answers oral/written questions about *their* contribution and the overall project. This spot-checks true comprehension and holds each accountable for both their AND the group's work.\n",
      "\n",
      "\n",
      "=== 2. Embedded “Microquizzes” ===\n",
      "\n",
      "- Frequent, Low-Stakes Quizzing: At milestones during group work, give quick, individual quizzes or online responses on the knowledge or skills developed in that phase. These are formative, inform instruction, and provide incentives for staying engaged.\n",
      "- Tie to Group Content: Make quiz content directly related to current group tasks, reinforcing that collaborative learning supports personal mastery.\n",
      "\n",
      "\n",
      "=== 3. Two-Stage Assessments ===\n",
      "\n",
      "- Collaborative + Individual Phases: Adopt a “two-stage test” approach: students first attempt a quiz/test individually, then immediately reattempt it in their groups, discussing and submitting a group answer. Weight grades, e.g., 70% individual, 30% group. This preserves teamwork but foregrounds individual effort. See: [Two-Stage Exams in STEM](https://www.cwsei.ubc.ca/resources/files/Two-stage_exams.pdf).\n",
      "\n",
      "\n",
      "=== 4. Peer & Self Reflection Focused on Learning, Not Just Process ===\n",
      "\n",
      "- Make part of the project grade reflective: students must honestly evaluate their own and their peers’ content mastery and teamwork, citing specifics (\"I learned X from Y's explanation of the process...\").\n",
      "\n",
      "\n",
      "=== 5. Autograded Tech Tools for Accountability ===\n",
      "\n",
      "- If feasible, use edtech platforms (Google Classroom, Edpuzzle, Kahoot, etc.) for short, targeted check-ins—ensuring fast feedback and easy tracking of individual understanding throughout the project cycle.\n",
      "\n",
      "\n",
      "=== 6. Rotating “Lead Teacher” Roles With Brief Tutorials ===\n",
      "\n",
      "- For especially tricky concepts, have “rotation leaders” prepare and teach ~5 minute tutorials to the group, then answer reflection questions individually. This builds buy-in and tests mastery.\n",
      "\n",
      "Summary Table:\n",
      "\n",
      "| Strategy                         | Teamwork Supported       | Individual Mastery Measured      | Practicality                          |\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "=== | ===\n",
      "| Hybrid assessment                 | Yes                      | Yes                              | Project tweaking                      |\n",
      "| Microquizzes                      | Yes (if aligned)         | Yes (quizzes)                    | Easy with tech/short paper quizzes    |\n",
      "| Two-stage tests                   | Yes                      | Yes                              | Needs planning, but efficient         |\n",
      "| Reflective peer/self-assessment   | Yes                      | Some (with strong rubrics)       | Quick, needs good prompts             |\n",
      "\n",
      "Final Advice:  \n",
      "Blend at least two of these in each project cycle. For instance: break group projects into sub-tasks, use solo checkpoints, and wrap up with a 2-stage quiz. This maximizes learning, maintains motivation, and keeps grading manageable!\n",
      "\n",
      "Let me know if you'd like templates or rubrics for any approach.\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output_prompt_engin(test_q)\n",
    "\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH Prompt Engineering ===\\n\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
