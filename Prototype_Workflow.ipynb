{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c0ebc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/huanxing/Documents/GitHub/Analogical-LLM/.conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f00062d-0f67-46b5-aca0-b7857d11c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "import openai \n",
    "# from langgraph_supervisor import create_supervisor\n",
    "from langchain.chat_models import init_chat_model\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9c75eb6-69bf-40c9-8ed4-8b96c4d1f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts\n",
    "TARGET_DOMAIN = dedent(\"\"\"\n",
    "        As a Domain Analysis Specialist, extract all the core innovation domains from the user query. It could be a single one for a simple query, or multiple ones for a complex query.\n",
    "        Instructions:\n",
    "        1. Analyze the user's input\n",
    "        2. Identify the primary domain(s) requiring innovation\n",
    "        3. Classify it within standard innovation categories\n",
    "        Output Format:\n",
    "        Target Domain: [Clear, specific domain label]\n",
    "        Be very detailed and specific in your response and do not generalize. Respond ONLY with the name of the domain, do NOT include ANY other text like 'Target Domain:'.\n",
    "        User query: {user_query}\n",
    "\"\"\").strip()\n",
    "\n",
    "PROBLEM_LANDSCAPE = dedent(\"\"\"\n",
    "        You are a Problem Landscape Analyst. Your task is to map out the concrete challenges within the target domain identified.\n",
    "        Instructions:\n",
    "        1. Identify all the core problems or challenges currently present in these domains. Aim for at least 3 problems per domain\n",
    "        2. For each problem, provide:\n",
    "        - Problem: A short, clear title.\n",
    "        - Description: 2-3 sentences explaining what the problem is and why it matters.\n",
    "        - Context: Briefly state the circumstances or environment where this problem occurs.\n",
    "        - Stakeholders: List the main groups or individuals affected.\n",
    "        - Root Causes: Identify 1-3 underlying causes, if known.\n",
    "        - Impact: State the significance of the problem (e.g., social, economic, technical).\n",
    "        - Current Approaches: How is this problem currently addressed?\n",
    "        - Limitations: What are the shortcomings of current approaches?\n",
    "        - Success Metrics: How would you measure if this problem is solved?\n",
    "        - Interconnections: Note if this problem is linked to or influenced by other problems.\n",
    "        Output Format:\n",
    "        Present your findings as a structured list or JSON array, with each problem fully described as above.\n",
    "        Important:\n",
    "        - Focus on clarity and completeness.\n",
    "        - Avoid abstracting or generalizing; stay concrete and domain-specific.\n",
    "        - Do not propose solutions; only describe the current problem landscape.\n",
    "        Target domain: {target_domain}\n",
    "\"\"\").strip()\n",
    "\n",
    "ABSTRACTION = dedent(\"\"\"\n",
    "You are a TRIZ Methodology Expert. Transform domain-specific problems into universal contradictions.\n",
    "        Process:\n",
    "        1. Read up on TRIZ - the contradiction matrix, and the inventive principles\n",
    "        2. For each problem in the problem landscape:\n",
    "        - Abstract to universal parameters (what improves vs. what worsens)\n",
    "        - Express as 'When we improve X, Y worsens'\n",
    "        - Ensure parameters are domain-agnostic\n",
    "        3. Analyze all the abstracted universal parameters, and identify all the core TRIZ contradictions present:\n",
    "        - Select the most fundamental tensions\n",
    "        - Map to TRIZ contradiction matrix\n",
    "        - Note applicable inventive principles\n",
    "        Output:\n",
    "        # List all the core contradictions in form of:\n",
    "        - Improving [parameter] vs. Worsening [parameter]\n",
    "        - TRIZ Principles: [1-3 relevant principles]\n",
    "        - Innovation Potential: [High/Medium/Low]\n",
    "        Focus on contradictions that, if resolved, would create breakthrough value.\n",
    "\n",
    "        Problem landscape: {problem_landscape}\n",
    "\"\"\").strip()\n",
    "\n",
    "BASE_DOMAIN = dedent(\"\"\"\n",
    "        You are a Cross-Domain Search Specialist. Do the following:\n",
    "        - For each contradiction provided, identify 3 distinct source domains (fields or industries) where this contradiction has been successfully addressed.\n",
    "        - Experiment with different subsets of the list of contradictions, and see if you could identify 3 distinct source domains for each of these subsets identified as well. You should find at least 3 different subsets.\n",
    "        Note: The domains should have A CONCEPTUAL DISTANCE OF AT LEAST 3 DISTINCT HOPS FROM WHAT IMMEDIATELY COMES TO MIND. Be creative! It can be domains within spheres like natural, phsyical, social, artistic, or anything.\n",
    "        For each domain identified, briefly explain why it is relevant to the single contradiction or the subset of contradictions identified. Do not describe specific solutions just yet-only list the domains and your rationale.\n",
    "        Output:\n",
    "        A list for each contradiction and subset of contradictions identified, naming 3 relevant domains with a 2 sentence rationale for each.\n",
    "        Aim for a total of at least 20 relevant base domains. \n",
    "        Contradictions: {contradictions}\n",
    "\"\"\").strip()\n",
    "\n",
    "BASE_SOLUTIONS = dedent(\"\"\"\n",
    "        You are a Solution Pattern Extractor. You are provided with an input with 3 base domains identified per TRIZ (Theory of Inventive Problem Solving) contradiction or a set of contradictions, as well as the contradictions themselves.\n",
    "        For each of these identified base domains, identify one specific, well-documented solution pattern within the domain that effectively resolves the contradiction (or the set of contradictions).\n",
    "        For each solution pattern, return:\n",
    "        - Identify the base domain it's corresponding to\n",
    "        - Recall the contradiction or the set of contradictions that this base domain faces\n",
    "        - The name or label of the solution pattern for resolving these contradiction(s) in the base domain\n",
    "        - A detailed description of the core mechanism or principle involved and how it addressed the domain's contradiction(s)\n",
    "        - The context or situation in the domain where this pattern is applied\\n\"\n",
    "        Do not generalize or adapt the solution-simply describe how the contradiction is addressed within each source domain.\n",
    "        Output:\n",
    "        For each of the provided domain, list the base domain name, contradiction(s) faced, solution pattern name, the detailed description of the mechanism of the solution pattern, and the context in which it is used. Articulate the contradictions as problems and considerations faced, through framing them as a tension.\n",
    "\n",
    "        Input: {input}\n",
    "\"\"\").strip()\n",
    "\n",
    "ANALOGICAL_TRANSFER = dedent(\"\"\"\n",
    "        You are a very innovative Analogical Transfer Specialist.\n",
    "        You are provided with list the base domain name, tensions faced, solution pattern name, the detailed description of the mechanism of the solution pattern, and the context in which it is used.\n",
    "        Your task is to propose how solution patterns used to resolve these tensions in various base domains might inspire solution framings for the original target domain.\n",
    "\n",
    "        Input Overview:\n",
    "        1. A list the base domains identified, the tensions these domains faced, the name of solution patterns that helped addressed these tensions in these base domains, the detailed description of the mechanism of the solution pattern, and the context in which it is used.\n",
    "        2. The original target domain.\n",
    "\n",
    "        Instructions:\n",
    "        For each pair of base domain and the corresponding tensions identified, review the solution patterns that worked for the base domain. For each pattern:\n",
    "        - Analyze the core mechanism or principle behind the solution.\n",
    "        - Map and adapt this mechanism conceptually to the target domain, considering the specific context and needs of the target domain.\n",
    "        - Clearly describe how this analogical transfer could frame a potential solution in the target domain.\n",
    "        - Highlight any key adaptations, considerations, or limitations that would be relevant when applying this pattern to the target domain.\n",
    "\n",
    "        Your expected Output:\n",
    "        For each base domain, provide a comprehensive description of a proposed solution framing for the target domain, including:\n",
    "        - The original tension addressed\n",
    "        - The source domain and solution pattern\n",
    "        - A detailed explanation of how the pattern could inspire or inform a solution in the target domain\n",
    "        - Any important adaptations or considerations for successful transfer\n",
    "\n",
    "        Here are the actualinputs:\n",
    "        - A list the base domains identified, the tensions these domains faced, the name of solution patterns that helped addressed these tensions in these base domains, the detailed description of the mechanism of the solution pattern, and the context in which it is used.: {contradictions_solutions}\n",
    "        - Original target domain: {target_domain}\n",
    "\"\"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e573d7e-e43f-4c7d-8752-ae11a6198c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for openai API\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a188a9e3-c538-487f-9dde-8dfe295575db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph state: workflow\n",
    "class ReasoningState(TypedDict):\n",
    "    user_query: str\n",
    "    target_domain: str\n",
    "    problem_landscape: str\n",
    "    abstraction: str\n",
    "    base_domain: str\n",
    "    base_solutions: str\n",
    "    analogical_transfer: str\n",
    "    solution: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "306439ab-4b94-4084-8a1c-8c53ecf1a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can switch between different LLMs \n",
    "llms = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54ea64a9-96a1-42ab-bb3d-1a1c1d14b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st Agent: Identify Target Domain from User Input\n",
    "def target_domain_agent(state: ReasoningState):\n",
    "    u = state['user_query']\n",
    "\n",
    "    msg = llms.invoke(TARGET_DOMAIN.format(user_query=u))\n",
    "\n",
    "    return {\"target_domain\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d327c06e-9618-4463-b19e-2be74a21d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2st Agent: Conduct comprehensive research into problem landscape for target domain \n",
    "# (i.e. What specific challenges exist in this domain?)\n",
    "def problem_landscape_agent(state: ReasoningState):\n",
    "    t = state['target_domain']\n",
    "\n",
    "    msg = llms.invoke(PROBLEM_LANDSCAPE.format(target_domain=t))\n",
    "\n",
    "    return {\"problem_landscape\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26b96ec9-7bdb-4803-9bab-dcc82d6a4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Agent: Abstract Problems Identified into Generalized Principles and TRIZ Contradiction\n",
    "def abstraction_agent(state: ReasoningState):\n",
    "    p = state['problem_landscape']\n",
    "\n",
    "    msg = llms.invoke(ABSTRACTION.format(problem_landscape=p))\n",
    "\n",
    "    return {\"abstraction\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e95a5d2f-1773-4339-ba89-995d185885c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th Agent: Search for Appropriate Base Domains\n",
    "def base_domain_agent(state: ReasoningState):\n",
    "    a = state['abstraction']\n",
    "\n",
    "    msg = llms.invoke(BASE_DOMAIN.format(contradictions=a))\n",
    "\n",
    "    return {\"base_domain\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7db11f3-e388-48b4-8661-cde636b1ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5th Agent: Identify Solution in Base Domain\n",
    "def base_solution_agent(state: ReasoningState):\n",
    "    b = state['base_domain']\n",
    "\n",
    "    msg = llms.invoke(BASE_SOLUTIONS.format(input=b))\n",
    "\n",
    "    return {\"base_solutions\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5dc1b395-b154-493e-9c57-7e5a6926cf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6th Agent: Base Domain Solution Informing Target Domain Solution\n",
    "def analogical_transfer_agent(state: ReasoningState):\n",
    "    if \"base_solutions\" not in state:\n",
    "        raise ValueError(\"Missing 'base_solutions' key. Check if previous node returned it.\")\n",
    "    b = state['base_solutions']\n",
    "    t = state['target_domain']\n",
    "    \n",
    "    msg = llms.invoke(ANALOGICAL_TRANSFER.format(contradictions_solutions=b, target_domain = t))\n",
    "\n",
    "    return {\"analogical_transfer\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3626041-fcd5-4bf3-a32b-f164352e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7th Agent: Summarize everything and respond to the question\n",
    "def synthesis_agent(state: ReasoningState):\n",
    "    msg = llms.invoke(\n",
    "        f\"Evaluate the proposed analogical solutions. Find the best ones that balances practicality with innovation. Then, provide a detailed, well-structured response that addresses all aspects of the query.\\n\\n\"\n",
    "        f\"Problem: {state['user_query']}\\n\"\n",
    "        f\"Analogical Solutions: {state['analogical_transfer']}\"\n",
    "        f\"In your output, remember to abstract away the analogy itself such that it is focused on responding to the user input.\"\n",
    "        f\"Also, check if the users are requesting a specific number of possible solutions. Make sure to answer the user's query in full and provide what is requested.\"\n",
    "    )\n",
    "    return {\"solution\": msg.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68994430-5388-4c63-84be-919d5978d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the workflow \n",
    "workflow = StateGraph(ReasoningState)\n",
    "\n",
    "workflow.add_node(\"target\", target_domain_agent)\n",
    "workflow.add_node(\"landscape\", problem_landscape_agent)\n",
    "workflow.add_node(\"abstract\", abstraction_agent)\n",
    "workflow.add_node(\"base\", base_domain_agent)\n",
    "workflow.add_node(\"base_soln\", base_solution_agent)\n",
    "workflow.add_node(\"analogy\", analogical_transfer_agent)\n",
    "workflow.add_node(\"synthesis\", synthesis_agent)\n",
    "\n",
    "workflow.set_entry_point(\"target\")\n",
    "\n",
    "# Define edges\n",
    "workflow.add_edge(\"target\", \"landscape\")\n",
    "workflow.add_edge(\"landscape\", \"abstract\")\n",
    "workflow.add_edge(\"abstract\", \"base\")\n",
    "workflow.add_edge(\"base\", \"base_soln\")\n",
    "workflow.add_edge(\"base_soln\", \"analogy\")\n",
    "workflow.add_edge(\"analogy\", \"synthesis\")\n",
    "\n",
    "workflow.set_finish_point(\"synthesis\")\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7fe14c",
   "metadata": {},
   "source": [
    "### Test my brainstorm prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5235345-734c-4aae-a32b-82acc97ddcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_q = \"I have an idea that I want to brainstorm with you. I'm not sure what problem I'm going to solve yet, but this is still something interesting to me. For background, I worked on a project called Anonymix, where we take a life story interview transcript from different individuals, convert these textual 'personas' to persona graph (with different types of nodes), and then identified graph clusters using louvain's method to shuffle them across personas to create shuffled persona. This preserves privacy while still making sure that individual agents are sufficiently realistic. Now, I'm going to work at whyhow.ai which is going to use knowledge graph RAG for enterprise use cases like legal and healthcare where accuracy and relevance of information retrieval is of paramount importance. I realised that graphs - knowledge graph in this case - are amazing tools that I want to learn more about. Specifically, I want to understand deeply, at a fundamental level, what *possibilities* it enables, and where might I be able to apply this to. For example, I guess I can take any sort of unstructured input and KG can construct a structured representation of them in a non-hierarchical manner. This is also the way that Roam Research and Logseq works and the core of their value proposition in terms of how they differ as a personal knowledge management system as compared to the hierarchical way of organising information that Notion or Evernote adopts. I can even imagine an enterprise or interpersonal use case, where IF everyone uses the same diary app that's private to themselves but me as the 'admin' behind the scene could see everything, then I could 'engineer serendipity' from, for example, identifying and suggesting to individuals with this same community that 'hey, person X is also thinking along similar lines as what you're thinking (but with a twist!). It'd be good to go find him for a chat, I'm sure you'll love it!'. This is 'engineered serendipity' that's still sufficiently serendipitous nevertheless because, for example, it's not just matching people based on what they PUBLICLY put out there but based on what they privately notes. Specifically, it tries to identify the common underlying 'values' and 'nuances' behind these private notes instead of connecting individuals based on the exact content of the private notes themselves. However, for this to work, I guess there need to have a common input channel that everything in the community would use, and I'm not sure how realistic is it going to be. Help me understand from first principles what this tech (representing ... as KG) might enable. The 'engineered serendipity' idea is an example of what I've thought of but it's not too practical yet. Then, after you've given me an in-depth exploration of the possibilities in terms of first principles, help me ideate 3 different project ideas I could actualize on. Give me rationale for why these might be difficult without the tech (representing ... as KG), an why the projects are tackling a real problem (rationale).  Let's explore the possibilities together!\"\n",
    "input_state = {\"user_query\": test_q}\n",
    "\n",
    "final_state = graph.invoke(input_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa161c-0873-49c4-9bcc-85d644311d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolutely! I love your background and thoughtful brainstorming. This is a rich, cutting-edge domain — knowledge graphs (KGs) unlock possibilities that are fundamentally different from hierarchical or even “flat” representations of information. Below, I'll walk you through a first-principles analysis of what knowledge graphs as a paradigm unlock — then we'll ideate three projects with rationales about why they're hard *without* KGs and what real-world pain they address.\n",
      "\n",
      "## 1. First Principles: What Do Knowledge Graphs Enable?\n",
      "\n",
      "Let’s break this down to fundamentals:\n",
      "\n",
      "### a) Flexible, Multidimensional Structuring\n",
      "\n",
      "- Traditional hierarchical structures (folders, trees) force you to choose a single “path” or classification for each item. KGs allow entities to have *multiple* relationships simultaneously, simulating how things work in reality (e.g., “Person X” can be a friend, a co-author, a patient, and a competitor at the same time) without duplication.\n",
      "- Enables polyhierarchies, rich ontologies, and relationships that can span types you hadn't foreseen up front.\n",
      "\n",
      "### b) Semantic Linking & Rich Context\n",
      "\n",
      "- In KGs, relationships can be typed and carry meaning (“is a”, “works at”, “disagrees with”, “mentored by”).\n",
      "- Contextual richness: not just what is related, but *how* and *why*.\n",
      "    - Example: “This scientist proposed ‘X’ which was later challenged by ‘Y’” and both are in context of discourse around “Z topic”.\n",
      "\n",
      "### c) Query Power and Reasoning\n",
      "\n",
      "- Unlike free text or rigid tables, you can ask nontrivial, even cross-cutting questions:\n",
      "    - “Show all legal cases involving both X and Y concepts cited by any two experts whose research overlaps on subset Z.”\n",
      "- Enables path-finding, inference, and analogical reasoning that flat or tree data can’t do.\n",
      "\n",
      "### d) Serendipity and Latent Discovery\n",
      "\n",
      "- Since all nodes and edges are explicitly modeled, surfacing unexpected links is natural.\n",
      "- Paths or bridges between seemingly disparate nodes (people, ideas) emerge, suggest new connections, insights, or serendipitous collaboration.\n",
      "- KGs do this inherently—this is why ‘engineered serendipity’ is possible!\n",
      "\n",
      "### e) Incremental, Non-Destructive Growth\n",
      "\n",
      "- Easy to extend: new node and relationship types as your understanding or use case evolves—no need to re-architect your whole knowledge representation.\n",
      "- Works well for collaborative, evolving domains where schema-in-advance fails.\n",
      "\n",
      "### f) Interoperability & Federation\n",
      "\n",
      "- KGs force you to “name and link”—this makes federated, cross-system, or community-wide knowledge sharing more practical.\n",
      "- Useful for integrating across orgs or platforms (e.g., legal + medical knowledge).\n",
      "\n",
      "\n",
      "=== ## 2. Project Possibilities (Based on These Principles) ===\n",
      "\n",
      "Here are 3 project ideas, each with a rationale for why KGs are key.\n",
      "\n",
      "### Project 1: Cross-Disciplinary Research Map for Enterprise R&D\n",
      "\n",
      "- Idea: Build a dynamic knowledge graph from research papers, internal documents, patents, emails, and Slack messages within a large org. The KG links topics, projects, people, findings, hypotheses, and underlying assumptions.\n",
      "- What’s hard w/o KGs: Hierarchical or search-based approaches bury vast “gray area” knowledge. You can't discover “hidden adjacencies”—people or teams working on the *same* underlying concept using different language or from different angles.\n",
      "- Painpoint Tackled: Prevents redundant work, accelerates innovation, surfaces analogies and novel collaborations, and identifies serendipitous connections (“Team B is using a similar approach you considered—talk to them before reinventing!”).\n",
      "\n",
      "### Project 2: Privacy-Preserving Mental Health Community with Pattern Discovery\n",
      "\n",
      "- Idea: Each user keeps a private, structured journal (e.g., via guided prompts), which is converted into a local KG of moods, values, events, triggers, activities. Backend performs de-identified, aggregated pattern mining on the graphs, spotting common progress loops, blockers, coping strategies.\n",
      "- What’s hard w/o KGs: Flat stats or NLP can only do basic sentiment and frequency counting. Subtle patterns, such as cycles of triggers and recoveries across individuals, are missed. KGs let you model and match progressions and feedback loops even with privacy constraints.\n",
      "- Painpoint Tackled: Mental health improvement depends on surfacing not just “what happened” but “how did change unfold” and “who is on a similar but slightly more advanced journey I could learn from?”—critical but nearly impossible without graph logic.\n",
      "\n",
      "### Project 3: Enterprise Policy Reasoning and Compliance Assistant\n",
      "\n",
      "- Idea: In enterprises (especially legal/healthcare), policies are sprawling documents. Each policy, exception, related law, and case is modeled as a graph. Whenever a user asks a question (“Can I share X data with Y under GDPR?”), the system finds and traverses the relevant reasoning path—explicitly showing precedents, exceptions, and edge cases.\n",
      "- What’s hard w/o KGs: Rule engines or keyword search often fail for exceptions, cross-references, and novel combinations. Decision trees grow unwieldy. Only KGs (with reasoning over them) can model intertwined policies and ‘why’ an answer applies based on all interrelated rules.\n",
      "- Painpoint Tackled: Dramatically reduces compliance bottlenecks and errors by making invisible dependencies and logic explicit and navigable.\n",
      "\n",
      "\n",
      "=== ## 3. Summary ===\n",
      "\n",
      "Why KGs Matter:  \n",
      "They fundamentally expand what you can model, reason about, and surface around *connections*, *contexts*, and *latent structure*, especially in messy, evolving, or highly interrelated environments. Serendipity, discovery, and deep insight become tractable, not accidental, as the structure itself reveals possible new paths, patterns, or nodes to focus on.\n",
      "\n",
      "Why Now:  \n",
      "Increasing data complexity, the rise of AI-powered extraction, and demand for “intelligence augmentation” means KGs’ time in enterprise and personal contexts is only just beginning!\n",
      "\n",
      "Feel free to expand or focus further—happy to do another ideation round or go technical/deep dive on any of these.\n"
     ]
    }
   ],
   "source": [
    "## Without analogical reasoning - raw LLM output\n",
    "result = basic_output(test_q)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25acee",
   "metadata": {},
   "source": [
    "### Test Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "750d99f1-e935-4250-82dd-d110d2e098e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_output\n",
    "import re\n",
    "\n",
    "def parse_solution(text):\n",
    "    # Remove Markdown formatting like \"**\" and \"\\n\"\n",
    "    clean_text = text.replace(\"**\", \"\").replace(\"\\\\n\", \"\\n\")\n",
    "\n",
    "    # Split into sections by horizontal rules (---)\n",
    "    sections = re.split(r'-{3,}', clean_text)\n",
    "\n",
    "    # Create a readable version of each section\n",
    "    readable_output = []\n",
    "    for section in sections:\n",
    "        section = section.strip()\n",
    "        if not section:\n",
    "            continue\n",
    "        # Optional: separate title and body if present\n",
    "        lines = section.split(\"\\n\")\n",
    "        if len(lines) > 1 and \":\" not in lines[0]:\n",
    "            # First line is likely a heading\n",
    "            heading = lines[0]\n",
    "            body = \"\\n\".join(lines[1:])\n",
    "            readable_output.append(f\"\\n=== {heading} ===\\n{body}\")\n",
    "        else:\n",
    "            readable_output.append(section)\n",
    "\n",
    "    return \"\\n\\n\".join(readable_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c40e70ac-30df-4ae1-bbfd-3b3cf4db43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all parsed outputs to a text file\n",
    "with open(\"sample_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for key in final_state:\n",
    "        raw_output = str(final_state[key])  # Ensure it's a string\n",
    "        final_output = parse_solution(raw_output)\n",
    "        f.write(f\"\\n### {key} ###\\n\")\n",
    "        f.write(final_output)\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b68a71d-9193-4005-ac65-5a668d06b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline for comparison\n",
    "def basic_output(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d5a4675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline ===\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output(test_q)\n",
    "\n",
    "## === GPT-4.1 Response Without Analogical Reasoning Pipeline ===\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline ===\\n\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4cde0abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline BUT WITH COT for comparison\n",
    "def basic_output_COT(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    Think step by step.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35361e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH COT ===\n",
      "\n",
      "Certainly! To address the problem—group work fostering teamwork but possibly reducing individual mastery/accountability—educators should reconsider both the design and assessment of group projects. Here’s a step-by-step approach:\n",
      "\n",
      "### Step 1: Diagnose the Core Issues\n",
      "- Observation: Individual post-project quizzes show lower scores than after solo work.\n",
      "- Analysis: Students may be \"hitchhiking\" (letting groupmates do more), or division of labor is masking some students’ conceptual gaps.\n",
      "\n",
      "### Step 2: Set Clear Dual Objectives\n",
      "- Maintain collaboration (teamwork, communication, problem-solving).\n",
      "- Ensure individual understanding and accountability (content mastery).\n",
      "\n",
      "### Step 3: Redesign Project Structure\n",
      "\n",
      "A. Roles and Responsibilities\n",
      "- Continue rotating roles but with defined individual deliverables for each phase.\n",
      "- Example: For a lab report, each student writes a different section (method, results, analysis) tied to understanding key concepts.\n",
      "\n",
      "B. Scaffolding Collaborative Work\n",
      "- Begin each project with an individual “readiness assurance” quiz to ensure base knowledge.\n",
      "- End with a group synthesis where students must teach back or present individually on certain components.\n",
      "\n",
      "### Step 4: Enhance Assessment Methods\n",
      "\n",
      "A. Mix of Individual and Group Grades\n",
      "- Assign a substantial portion (50–70%) of the project grade to individual performance (individual write-ups, oral defenses, or quizzes covering all project content).\n",
      "- The rest can be group-based (final artifact, group process, creativity).\n",
      "\n",
      "B. Individual Accountability During Projects\n",
      "- Use random “spot-checks”: At intervals, ask individuals to explain group decisions or data to the teacher or peers.\n",
      "- Incorporate short, unannounced individual quizzes on group project content.\n",
      "\n",
      "C. Peer Teaching\n",
      "- Each student is responsible for mastering and teaching one aspect of the project to their peers—accountability built-in.\n",
      "\n",
      "D. Reflection Components\n",
      "- Require individual reflections: “What did you learn? Which parts did you struggle with? How did you contribute?” Grade for depth and honesty.\n",
      "\n",
      "### Step 5: Provide Transparency and Feedback\n",
      "- Clearly communicate grading rubrics differentiating individual vs. group components.\n",
      "- Give quick feedback on readiness quizzes so students know where to focus.\n",
      "\n",
      "### Step 6: Monitor and Iterate\n",
      "- After implementing, monitor quiz scores, student feedback, and engagement.\n",
      "- Adjust the ratio of individual:group assessments or frequency of checks as needed.\n",
      "\n",
      "\n",
      "=== ### Sample Project Structure ===\n",
      "\n",
      "| Phase         | Activity           | Accountability Method            | Weight |\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "=== | ===\n",
      "| Project Start | Readiness Quiz     | Individual quiz                  | 20%    |\n",
      "| Project Work  | Group tasks        | Individual section + group work  | 30%    |\n",
      "| Midpoint      | Spot-check/explain | Give oral/written explanation    | 10%    |\n",
      "| Project End   | Group presentation | Individual Q&A (oral exam)       | 20%    |\n",
      "| Post-project  | Individual reflection/quiz | Reflection/quiz        | 20%    |\n",
      "\n",
      "In summary:  \n",
      "Blend group and individual tasks and assessments throughout the project. Ensure individual mastery is measured separately, but still tied to collaborative experiences. Adjust and iterate until you find a balance for your students.\n",
      "\n",
      "Further Reading:  \n",
      "- “Cooperative Learning: Improving University Instruction by Basing Practice on Validated Theory” (Millis, 2010)\n",
      "- “Designing Group Work: Strategies for the Heterogeneous Classroom” (Cohen & Lotan, 2014)\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output_COT(test_q)\n",
    "\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH COT ===\\n\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7f3ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output without analogical reasoning Pipeline BUT WITH PROMPT ENGINEERING for comparison (ask it to balance innovativeness with practicality)\n",
    "def basic_output_prompt_engin(user_input: str):\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    {user_input}\n",
    "    Try to balance practicality with innovation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llms.invoke(prompt) \n",
    "\n",
    "    # Parse and format the response\n",
    "    formatted_response = parse_solution(response.content)\n",
    "\n",
    "    return(formatted_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e85f2167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH Prompt Engineering ===\n",
      "\n",
      "Certainly! Balancing individual accountability with authentic collaboration is a common challenge in group work. Here’s a multi-pronged, practical-yet-innovative redesign educators can consider:\n",
      "\n",
      "\n",
      "=== 1. Hybrid Assessment Model ===\n",
      "\n",
      "- Personal Assignments Within Group Projects: Structure group projects so that each student is responsible for a distinct sub-task, deliverable, or research component. For example, in a biology project on ecosystems, one might investigate plant species, another animal relationships, etc. Require each member to submit a short individual report, reflection, or data analysis alongside the collective assignment.\n",
      "- Individual “Defense”: After project completion, each student briefly presents or answers oral/written questions about *their* contribution and the overall project. This spot-checks true comprehension and holds each accountable for both their AND the group's work.\n",
      "\n",
      "\n",
      "=== 2. Embedded “Microquizzes” ===\n",
      "\n",
      "- Frequent, Low-Stakes Quizzing: At milestones during group work, give quick, individual quizzes or online responses on the knowledge or skills developed in that phase. These are formative, inform instruction, and provide incentives for staying engaged.\n",
      "- Tie to Group Content: Make quiz content directly related to current group tasks, reinforcing that collaborative learning supports personal mastery.\n",
      "\n",
      "\n",
      "=== 3. Two-Stage Assessments ===\n",
      "\n",
      "- Collaborative + Individual Phases: Adopt a “two-stage test” approach: students first attempt a quiz/test individually, then immediately reattempt it in their groups, discussing and submitting a group answer. Weight grades, e.g., 70% individual, 30% group. This preserves teamwork but foregrounds individual effort. See: [Two-Stage Exams in STEM](https://www.cwsei.ubc.ca/resources/files/Two-stage_exams.pdf).\n",
      "\n",
      "\n",
      "=== 4. Peer & Self Reflection Focused on Learning, Not Just Process ===\n",
      "\n",
      "- Make part of the project grade reflective: students must honestly evaluate their own and their peers’ content mastery and teamwork, citing specifics (\"I learned X from Y's explanation of the process...\").\n",
      "\n",
      "\n",
      "=== 5. Autograded Tech Tools for Accountability ===\n",
      "\n",
      "- If feasible, use edtech platforms (Google Classroom, Edpuzzle, Kahoot, etc.) for short, targeted check-ins—ensuring fast feedback and easy tracking of individual understanding throughout the project cycle.\n",
      "\n",
      "\n",
      "=== 6. Rotating “Lead Teacher” Roles With Brief Tutorials ===\n",
      "\n",
      "- For especially tricky concepts, have “rotation leaders” prepare and teach ~5 minute tutorials to the group, then answer reflection questions individually. This builds buy-in and tests mastery.\n",
      "\n",
      "Summary Table:\n",
      "\n",
      "| Strategy                         | Teamwork Supported       | Individual Mastery Measured      | Practicality                          |\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "=== | ===\n",
      "| Hybrid assessment                 | Yes                      | Yes                              | Project tweaking                      |\n",
      "| Microquizzes                      | Yes (if aligned)         | Yes (quizzes)                    | Easy with tech/short paper quizzes    |\n",
      "| Two-stage tests                   | Yes                      | Yes                              | Needs planning, but efficient         |\n",
      "| Reflective peer/self-assessment   | Yes                      | Some (with strong rubrics)       | Quick, needs good prompts             |\n",
      "\n",
      "Final Advice:  \n",
      "Blend at least two of these in each project cycle. For instance: break group projects into sub-tasks, use solo checkpoints, and wrap up with a 2-stage quiz. This maximizes learning, maintains motivation, and keeps grading manageable!\n",
      "\n",
      "Let me know if you'd like templates or rubrics for any approach.\n"
     ]
    }
   ],
   "source": [
    "test_q = \"Teachers introduced structured group projects using peer evaluations and rotating roles to boost collaboration in science classes. Despite these measures, anonymous student surveys revealed that individual quiz scores post-project dropped compared to solo assignments, signaling diluted accountability. How can educators redesign design a system to ensure measurable individual mastery while preserving the benefits of teamwork?\"\n",
    "result = basic_output_prompt_engin(test_q)\n",
    "\n",
    "print(\"\\n=== GPT-4.1 Response Without Analogical Reasoning Pipeline WITH Prompt Engineering ===\\n\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analogical-lc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
